\chapter{Algorithms}\label{chap:appendix-algo}

Find here concrete implementation details on the EFTs described
in Theorem~\ref{thm:eft}. They do not use branches, nor access to the
mantissa that can be time-consuming.

\begin{breakablealgorithm}
  \caption{\textit{EFT of the sum of two floating point numbers.}}

  \begin{algorithmic}
    \Function{\(\left[S, \sigma\right] = \mathtt{TwoSum}\)}{$a, b$}
      \State \(S = a \oplus b\)
      \State \(z = S \ominus a\)
      \State \(\sigma = (a \ominus (S \ominus z)) \oplus (b \ominus z)\)
    \EndFunction
  \end{algorithmic}
\end{breakablealgorithm}

\noindent In order to avoid branching to check which among
\(\left|a\right|, \left|b\right|\) is largest, \texttt{TwoSum} uses 6 flops
rather than 3.

\begin{breakablealgorithm}
  \caption{\textit{Splitting of a floating point number into two parts.}}

  \begin{algorithmic}
    \Function{\(\left[h, \ell\right] = \mathtt{Split}\)}{$a$}
      \State \(z = a \otimes (2^r + 1)\)
      \State \(h = z \ominus (z \ominus a)\)
      \State \(\ell = a \ominus h\)
    \EndFunction
  \end{algorithmic}
\end{breakablealgorithm}

\noindent For IEEE-754 double precision floating point number, \(r = 27\)
so \(2^r + 1\) will be known before \texttt{Split} is called. In all,
\texttt{Split} uses 4 flops.

\begin{breakablealgorithm}
  \caption{\textit{EFT of the product of two floating point numbers.}}

  \begin{algorithmic}
    \Function{\(\left[P, \pi\right] = \mathtt{TwoProd}\)}{$a, b$}
      \State \(P = a \otimes b\)
      \State \(\left[a_h, a_{\ell}\right] = \mathtt{Split}(a)\)
      \State \(\left[b_h, b_{\ell}\right] = \mathtt{Split}(b)\)
      \State \(\pi = a_{\ell} \otimes b_{\ell} \ominus (((P \ominus
          a_h \otimes b_h)
          \ominus a_{\ell} \otimes b_h) \ominus a_h \otimes b_{\ell})\)
    \EndFunction
  \end{algorithmic}
\end{breakablealgorithm}

\noindent This implementation of \texttt{TwoProd} requires 17 flops.
For processors that provide a fused-multipy-add operator (\texttt{FMA}),
\texttt{TwoProd} can be rewritten to use only 2 flops:

\begin{breakablealgorithm}
  \caption{\textit{EFT of the sum of two floating point numbers with a FMA.}}
  \label{alg:two-prod-fma}

  \begin{algorithmic}
    \Function{\(\left[P, \pi\right] = \mathtt{TwoProdFMA}\)}{$a, b$}
      \State \(P = a \otimes b\)
      \State \(\pi = \mathtt{FMA}(a, b, -P)\)
    \EndFunction
  \end{algorithmic}
\end{breakablealgorithm}

\noindent The following algorithms from \cite{Ogita2005} can be used as a
compensated method for computing a sum of numbers. The first is a vector
transformation that is used as a helper:

\begin{breakablealgorithm}
  \caption{\textit{Error-free vector transformation for summation.}}
  \label{alg:vec-sum}

  \begin{algorithmic}
    \Function{\(\mathtt{VecSum}\)}{$p$}
      \State \(n = \texttt{length}(p)\)
      \For{\(j = 2, \ldots, n\)}
        \State \(\left[p_j, p_{j - 1}\right] = \mathtt{TwoSum}\left(
            p_j, p_{j - 1}\right)\)
      \EndFor
    \EndFunction
  \end{algorithmic}
\end{breakablealgorithm}

\noindent The second (\texttt{SumK}) computes a sum with results that are as
accurate as if computed in \(K\) times the working precision. It requires
\((6K - 5)(n - 1)\) floating point operations.

\begin{breakablealgorithm}
  \caption{\textit{Summation as in K-fold precision
      by \((K - 1)\)-fold error-free vector transformation.}}
  \label{alg:sum-k}

  \begin{algorithmic}
    \Function{\(\mathtt{result} = \mathtt{SumK}\)}{$p, K$}
      \For{\(j = 1, \ldots, K - 1\)}
        \State \(p = \mathtt{VecSum}(p)\)
      \EndFor
      \State \(\mathtt{result} = p_1 \oplus p_2 \oplus \cdots \oplus p_n\)
    \EndFunction
  \end{algorithmic}
\end{breakablealgorithm}

\noindent Since the final error \(\cdb{K - 1}\) will not track the errors
during computation, we have a non-EFT version of
Algorithm~\ref{alg:local-error-eft}:

\begin{breakablealgorithm}
  \caption{\textit{Compute the local error (non-EFT).}}
  \label{alg:local-error}

  \begin{algorithmic}
    \Function{\(\widehat{\ell} =
        \mathtt{LocalError}\)}{$e, \rho, \delta b$}
      \State \(L = \texttt{length}(e)\)
      \\
      \State \(\widehat{\ell} = e_1 \oplus e_2\)
      \For{\(j = 3, \ldots, L\)}
        \State \(\widehat{\ell} = \widehat{\ell} \oplus e_j\)
      \EndFor
      \\
      \State \(\widehat{\ell} = \widehat{\ell} \oplus \left(
          \rho \otimes \delta b\right)\)
    \EndFunction
  \end{algorithmic}
\end{breakablealgorithm}

In order to discuss varied implementations of Newton's method in
Chapter~\ref{chap:compensated-newton}, we define a generic algorithm
that takes an ``update function'' (\(\mathtt{update\_fn}\)), i.e.
a callable that will produce the next Newton update \(p(s) / p'(s)\)
computed in a problem-specific way.

\begin{breakablealgorithm}
  \caption{\textit{Generic Newton's method for scalar functions.}}
  \label{alg:generic-newton}

  \begin{algorithmic}
    \Function{\(x_{\ast} = \mathtt{NewtonGeneric}\)}
             {$\mathtt{update\_fn}, x_0, \mathtt{tol}, \mathtt{max\_iter}$}
      \State \(x = x_0\)
      \\
      \For{\(j = 1, \ldots, \mathtt{max\_iter}\)}
        \State \(\mathtt{update} = \mathtt{update\_fn}(x)\)
        \State \(x = x \ominus \mathtt{update}\)
        \If{\(\left|\mathtt{update}\right| < \mathtt{tol}\)}
          \State \textbf{break}
        \EndIf
      \EndFor
      \\
      \State \(x_{\ast} = x\)
    \EndFunction
  \end{algorithmic}
\end{breakablealgorithm}

In \cite[Algorithm~3]{Jiang2010}, the \texttt{CompDeCasteljau} (
Algorithm~\ref{alg:comp-de-casteljau}) is modified for the computation
of the derivative \(p'(s)\). Since \(p'(s)\) has coefficients
\(n \Delta b_j\) where \(c_j = \Delta b_j = b_{j + 1} - b_j\),
we can begin the computation with nonzero
\(\widehat{\partial c}_j\) (as opposed to
\(\cdb{1}_j^{(n)} = 0\) in \texttt{CompDeCasteljau}).

\begin{breakablealgorithm}
  \caption{\textit{Compensated de Casteljau
      algorithm for polynomial first derivative evaluation.}}
  \label{alg:comp-de-casteljau-derivative}

  \begin{algorithmic}
    \Function{\(\mathtt{result} = \mathtt{CompDeCasteljauDer}\)}{$b, s$}
      \State \(n = \texttt{length}(b) - 1\)
      \State \(\left[\widehat{r}, \rho\right] = \mathtt{TwoSum}(1, -s)\)
      \\
      \For{\(j = 0, \ldots, n - 1\)}
        \State \(\left[\widehat{c}_j^{(n - 1)},
          \widehat{\partial c}_j^{(n - 1)}\right] =
          \mathtt{TwoSum}(b_{j + 1}, -b_j)\)
      \EndFor
      \\
      \For{\(k = n - 2, \ldots, 0\)}
        \For{\(j = 0, \ldots, k\)}
          \State \(\left[P_1, \pi_1\right] = \mathtt{TwoProd}\left(
              \widehat{r}, \widehat{c}_j^{(k + 1)}\right)\)
          \State \(\left[P_2, \pi_2\right] = \mathtt{TwoProd}\left(
              s, \widehat{c}_{j + 1}^{(k + 1)}\right)\)
          \State \(\left[\widehat{c}_j^{(k)}, \sigma_3\right] =
              \mathtt{TwoSum}(P_1, P_2)\)
          \State \(\widehat{\ell}_{1, j}^{(k)} = \pi_1 \oplus \pi_2 \oplus
              \sigma_3 \oplus \left(\rho \otimes
              \widehat{c}_j^{(k + 1)}\right)\)
          \State \(\widehat{\partial c}_j^{(k)} =
              \widehat{\ell}_{1, j}^{(k)} \oplus
              \left(s \otimes \widehat{\partial c}_{j + 1}^{(k + 1)}
              \right) \oplus
              \left(\widehat{r} \otimes
              \widehat{\partial c}_j^{(k + 1)}\right)\)
        \EndFor
      \EndFor
      \\
      \State \(\mathtt{result} = n \otimes \left[\widehat{c}_0^{(0)} \oplus
          \widehat{\partial c}_0^{(0)}\right]\)
    \EndFunction
  \end{algorithmic}
\end{breakablealgorithm}

For an applied usage of \texttt{CompDeCasteljau}
(Algorithm~\ref{alg:comp-de-casteljau}) in
Chapter~\ref{chap:compensated-newton}, both the non-compensated
value \(\widehat{b}\) and the compensation term \(\widehat{\partial b}\) are
needed. So we define a partial EFT. We say \textbf{partial} because
the compensation term is rounded.

\begin{breakablealgorithm}
  \caption{\textit{EFT for de Casteljau algorithm for polynomial evaluation.}}
  \label{alg:eft-de-casteljau}

  \begin{algorithmic}
    \Function{\(\left[\widehat{b}, \widehat{\partial b}\right] =
      \mathtt{DeCasteljauEFT}\)}{$b, s$}
      \State \(n = \texttt{length}(b) - 1\)
      \State \(\left[\widehat{r}, \rho\right] = \mathtt{TwoSum}(1, -s)\)
      \\
      \For{\(j = 0, \ldots, n\)}
        \State \(\widehat{b}_j^{(n)} = b_j\)
        \State \(\cdb{1}_j^{(n)} = 0\)
      \EndFor
      \\
      \For{\(k = n - 1, \ldots, 0\)}
        \For{\(j = 0, \ldots, k\)}
          \State \(\left[P_1, \pi_1\right] = \mathtt{TwoProd}\left(
              \widehat{r}, \widehat{b}_j^{(k + 1)}\right)\)
          \State \(\left[P_2, \pi_2\right] = \mathtt{TwoProd}\left(
              s, \widehat{b}_{j + 1}^{(k + 1)}\right)\)
          \State \(\left[\widehat{b}_j^{(k)}, \sigma_3\right] =
              \mathtt{TwoSum}(P_1, P_2)\)
          \State \(\widehat{\ell}_{1, j}^{(k)} = \pi_1 \oplus \pi_2 \oplus
              \sigma_3 \oplus \left(\rho \otimes
              \widehat{b}_j^{(k + 1)}\right)\)
          \State \(\cdb{1}_j^{(k)} =
              \widehat{\ell}_{1, j}^{(k)} \oplus
              \left(s \otimes \cdb{1}_{j + 1}^{(k + 1)}
              \right) \oplus
              \left(\widehat{r} \otimes
              \cdb{1}_j^{(k + 1)}\right)\)
        \EndFor
      \EndFor
      \\
      \State \(\widehat{b} = \widehat{b}_0^{(0)}\)
      \State \(\widehat{\partial b} = \cdb{1}_0^{(0)}\)
    \EndFunction
  \end{algorithmic}
\end{breakablealgorithm}
